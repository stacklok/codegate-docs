We recommend the [Qwen2.5-Coder](https://ollama.com/library/qwen2.5-coder)
series of models. Our minimum recommendation for quality results is the 7
billion parameter (7B) version, `qwen2.5-coder:7b-instruct`. This model balances
performance and quality for systems with at least 4 CPU cores and 16GB of RAM.
If you have more compute resources available, our experimentation shows that
larger models do yield better results.
